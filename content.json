{"meta":{"title":"Cxy's Blog","subtitle":"","description":"","author":"Cui Xinyu","url":"https://proton991.github.io","root":"/"},"pages":[{"title":"关于","date":"2022-06-17T03:00:36.044Z","updated":"2022-06-17T03:00:36.044Z","comments":false,"path":"about/index.html","permalink":"https://proton991.github.io/about/index.html","excerpt":"","text":"About Me个人详细介绍"},{"title":"分类","date":"2022-06-17T03:00:36.044Z","updated":"2022-06-17T03:00:36.044Z","comments":false,"path":"categories/index.html","permalink":"https://proton991.github.io/categories/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-06-17T03:00:36.044Z","updated":"2022-06-17T03:00:36.044Z","comments":false,"path":"repository/index.html","permalink":"https://proton991.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-06-17T03:00:36.044Z","updated":"2022-06-17T03:00:36.044Z","comments":false,"path":"tags/index.html","permalink":"https://proton991.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Ark VkRenderer Dev Log 6","slug":"Ark-VkRenderer-Dev-Log-6","date":"2022-07-05T12:25:40.000Z","updated":"2022-07-05T13:18:00.684Z","comments":false,"path":"Ark-VkRenderer-Dev-Log-6/","link":"","permalink":"https://proton991.github.io/Ark-VkRenderer-Dev-Log-6/","excerpt":"","text":"FramebuffersFirst, create another std::vector class member to hold the framebuffers: 1std::vector&lt;VkFramebuffer&gt; m_swapChainFrameBuffers; Start by resizing the container to hold all of the framebuffers: 1m_swapChainFrameBuffers.resize(ImageCount()); We’ll then iterate through the image views and create framebuffers from them: 1234567891011121314151617181920212223242526for (size_t i = 0; i &lt; ImageCount(); i++)&#123; std::array&lt;VkImageView, 2&gt; attachments = &#123; m_swapChainImageViews[i], m_depthImageViews[i] &#125;; VkExtent2D swapChainExtent = GetSwapChainExtent(); VkFramebufferCreateInfo framebufferInfo = &#123;&#125;; framebufferInfo.sType = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO; framebufferInfo.renderPass = m_renderPass; framebufferInfo.attachmentCount = static_cast&lt;uint32_t&gt;(attachments. size()); framebufferInfo.pAttachments = attachments.data(); framebufferInfo.width = swapChainExtent.width; framebufferInfo.height = swapChainExtent.height; framebufferInfo.layers = 1; if (vkCreateFramebuffer( m_device.Device(), &amp;framebufferInfo, nullptr, &amp;m_swapChainFrameBuffers[i]) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create framebuffer!&quot;); &#125;&#125; Don’t forget to destroy the framebuffers: 1234for (auto framebuffer : m_swapChainFrameBuffers)&#123; vkDestroyFramebuffer(m_device.Device(), framebuffer, nullptr);&#125; Command buffersCommands in Vulkan, like drawing operations and memory transfers, are not executed directly using function calls. You have to record all of the operations you want to perform in command buffer objects. The advantage of this is that when we are ready to tell the Vulkan what we want to do, all of the commands are submitted together and Vulkan can more efficiently process the commands since all of them are available together. In addition, this allows command recording to happen in multiple threads if so desired. Command poolsTo use command buffers, we must create a command pool. Command pools manage the memory that is used to store the buffers and command buffers are allocated from them. We use vkCreateCommandPool to create a command pool, first look at its prototype: 12345VkResult vkCreateCommandPool( VkDevice device, const VkCommandPoolCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkCommandPool* pCommandPool); This function takes in a logical device as its first parameter, so we place this function and m_commandPool in ArkDeivce.hpp: 1234567891011121314151617void ArkDevice::CreateCommandPool()&#123; QueueFamilyIndices queueFamilyIndices = FindPhysicalQueueFamilies(); VkCommandPoolCreateInfo poolInfo = &#123;&#125;; poolInfo.sType = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO; poolInfo.queueFamilyIndex = queueFamilyIndices.m_graphicsFamily; poolInfo.flags = VK_COMMAND_POOL_CREATE_TRANSIENT_BIT | VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT; if (vkCreateCommandPool(m_device, &amp;poolInfo, nullptr, &amp;m_commandPool) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create command pool!&quot;); &#125;&#125; You can see that the createXXX pattern is quite similar in Vulkan API. In our FirstApp.hpp, implement CreateCommandBuffers(): 1234567891011121314151617181920212223242526272829303132333435363738394041424344void FirstApp::CreateCommandBuffers()&#123; m_commandBuffers.resize(m_arkSwapChain.ImageCount()); VkCommandBufferAllocateInfo allocateInfo&#123;&#125;; allocateInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO; allocateInfo.level = VK_COMMAND_BUFFER_LEVEL_PRIMARY; allocateInfo.commandPool = m_arkDevice.GetCommandPool(); allocateInfo.commandBufferCount = static_cast&lt;uint32_t&gt;(m_commandBuffers.size()); if (vkAllocateCommandBuffers(m_arkDevice.Device(), &amp;allocateInfo, m_commandBuffers.data()) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to allocate command buffers!&quot;); &#125; for (int i = 0; i &lt; m_commandBuffers.size(); ++i) &#123; VkCommandBufferBeginInfo beginInfo&#123;&#125;; beginInfo.sType = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO; if (vkBeginCommandBuffer(m_commandBuffers[i], &amp;beginInfo) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to begin recording command buffers!&quot;); &#125; VkRenderPassBeginInfo renderPassInfo&#123;&#125;; renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO; renderPassInfo.renderPass = m_arkSwapChain.GetRenderPass(); renderPassInfo.framebuffer = m_arkSwapChain.GetFrameBuffer(i); renderPassInfo.renderArea.offset = &#123; 0, 0 &#125;; renderPassInfo.renderArea.extent = m_arkSwapChain.GetSwapChainExtent(); std::array&lt;VkClearValue, 2&gt; clearValues&#123;&#125;; clearValues[0].color = &#123;0.1f, 0.1f, 0.1f, 1.0f&#125;; clearValues[1].depthStencil = &#123; 1.0f, 0 &#125;; renderPassInfo.clearValueCount = static_cast&lt;uint32_t&gt;(clearValues.size()); renderPassInfo.pClearValues = clearValues.data(); vkCmdBeginRenderPass(m_commandBuffers[i], &amp;renderPassInfo, VK_SUBPASS_CONTENTS_INLINE); m_arkPipeline-&gt;Bind(m_commandBuffers[i]); vkCmdDraw(m_commandBuffers[i], 3, 1, 0, 0); vkCmdEndRenderPass(m_commandBuffers[i]); if (vkEndCommandBuffer(m_commandBuffers[i]) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to record command buffer!&quot;); &#125; &#125;&#125; Draw our triangleNow it’s time to present our triangle: 1234567891011121314void FirstApp::DrawFrame()&#123; uint32_t imageIndex; auto result = m_arkSwapChain.AcquireNextImage(&amp;imageIndex); if (result != VK_SUCCESS &amp;&amp; result != VK_SUBOPTIMAL_KHR) &#123; throw std::runtime_error(&quot;failed to acquire swap chain image!&quot;); &#125; result = m_arkSwapChain.SubmitCommandBuffers(&amp;m_commandBuffers[imageIndex], &amp;imageIndex); if (result != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to represent swap chain image!&quot;); &#125;&#125; SubmitCommandBUffers function: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859VkResult ArkSwapChain::SubmitCommandBuffers( const VkCommandBuffer* buffers, uint32_t* imageIndex)&#123; if (m_imagesInFlight[*imageIndex] != VK_NULL_HANDLE) &#123; vkWaitForFences(m_device.Device(), 1, &amp;m_imagesInFlight[*imageIndex], VK_TRUE, UINT64_MAX); &#125; m_imagesInFlight[*imageIndex] = m_inFlightFences[m_currentFrame]; // Queue submission and synchronization VkSubmitInfo submitInfo = &#123;&#125;; submitInfo.sType = VK_STRUCTURE_TYPE_SUBMIT_INFO; VkSemaphore waitSemaphores[] = &#123; m_imageAvailableSemaphores[m_currentFrame] &#125;; VkPipelineStageFlags waitStages[] = &#123; VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT &#125;; submitInfo.waitSemaphoreCount = 1; submitInfo.pWaitSemaphores = waitSemaphores; submitInfo.pWaitDstStageMask = waitStages; submitInfo.commandBufferCount = 1; submitInfo.pCommandBuffers = buffers; VkSemaphore signalSemaphores[] = &#123; m_renderFinishedSemaphores[m_currentFrame] &#125;; submitInfo.signalSemaphoreCount = 1; submitInfo.pSignalSemaphores = signalSemaphores; vkResetFences(m_device.Device(), 1, &amp;m_inFlightFences[m_currentFrame]); if (vkQueueSubmit(m_device.GraphicsQueue(), 1, &amp;submitInfo, m_inFlightFences[m_currentFrame]) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to submit draw command buffer!&quot;); &#125; VkPresentInfoKHR presentInfo = &#123;&#125;; presentInfo.sType = VK_STRUCTURE_TYPE_PRESENT_INFO_KHR; presentInfo.waitSemaphoreCount = 1; presentInfo.pWaitSemaphores = signalSemaphores; VkSwapchainKHR swapChains[] = &#123;m_swapChain&#125;; presentInfo.swapchainCount = 1; presentInfo.pSwapchains = swapChains; presentInfo.pImageIndices = imageIndex; auto result = vkQueuePresentKHR(m_device.PresentQueue(), &amp;presentInfo); m_currentFrame = (m_currentFrame + 1) % MAX_FRAMES_IN_FLIGHT; return result;&#125; The synchronization in Vulkan is a little complicated, we will discuss it in a separate post.","categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"Vulkan","slug":"Vulkan","permalink":"https://proton991.github.io/tags/Vulkan/"}]},{"title":"Ark VkRenderer Dev Log 5","slug":"Ark-VkRenderer-Dev-Log-5","date":"2022-07-05T09:16:11.000Z","updated":"2022-07-05T11:00:40.914Z","comments":false,"path":"Ark-VkRenderer-Dev-Log-5/","link":"","permalink":"https://proton991.github.io/Ark-VkRenderer-Dev-Log-5/","excerpt":"","text":"Render passesBefore we can finish creating the pipeline, we need to tell Vulkan about the framebuffer attachments that will be used while rendering. We need to specify how many color and depth buffers there will be, how many samples to use for each of them and how their contents should be handled throughout the rendering operations. We need VkAttachmentDescription and VkAttachmentReference. VkSubpassDescription is stored in render pass object and VkAttachmentReference is stored in sub passes. Making it possible for sub passes to reference the same attachment. When specifying VkAttachmentReference, the attachment parameter specifies which attachment to reference by its index in the attachment descriptions array. In this simple example, we have 0 for colorAttachmentRef and 1 for depthAttachmentRef. Here is the complete code: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071void ArkSwapChain::CreateRenderPass()&#123; VkAttachmentDescription depthAttachment&#123;&#125;; depthAttachment.format = FindDepthFormat(); depthAttachment.samples = VK_SAMPLE_COUNT_1_BIT; depthAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR; depthAttachment.storeOp = VK_ATTACHMENT_STORE_OP_DONT_CARE; depthAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE; depthAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE; depthAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED; depthAttachment.finalLayout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL; VkAttachmentReference depthAttachmentRef&#123;&#125;; depthAttachmentRef.attachment = 1; depthAttachmentRef.layout = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL; VkAttachmentDescription colorAttachment = &#123;&#125;; colorAttachment.format = GetSwapChainImageFormat(); colorAttachment.samples = VK_SAMPLE_COUNT_1_BIT; colorAttachment.loadOp = VK_ATTACHMENT_LOAD_OP_CLEAR; colorAttachment.storeOp = VK_ATTACHMENT_STORE_OP_STORE; colorAttachment.stencilStoreOp = VK_ATTACHMENT_STORE_OP_DONT_CARE; colorAttachment.stencilLoadOp = VK_ATTACHMENT_LOAD_OP_DONT_CARE; colorAttachment.initialLayout = VK_IMAGE_LAYOUT_UNDEFINED; colorAttachment.finalLayout = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR; VkAttachmentReference colorAttachmentRef = &#123;&#125;; colorAttachmentRef.attachment = 0; colorAttachmentRef.layout = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL; VkSubpassDescription subpass = &#123;&#125;; subpass.pipelineBindPoint = VK_PIPELINE_BIND_POINT_GRAPHICS; subpass.colorAttachmentCount = 1; subpass.pColorAttachments = &amp;colorAttachmentRef; subpass.pDepthStencilAttachment = &amp;depthAttachmentRef; VkSubpassDependency dependency = &#123;&#125;; dependency.srcSubpass = VK_SUBPASS_EXTERNAL; dependency.srcAccessMask = 0; dependency.srcStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT | VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT; dependency.dstSubpass = 0; dependency.dstStageMask = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT | VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT; dependency.dstAccessMask = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT | VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT; std::array&lt;VkAttachmentDescription, 2&gt; attachments = &#123; colorAttachment, depthAttachment &#125;; VkRenderPassCreateInfo renderPassInfo = &#123;&#125;; renderPassInfo.sType = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO; renderPassInfo.attachmentCount = static_cast&lt;uint32_t&gt;(attachments. size()); renderPassInfo.pAttachments = attachments.data(); renderPassInfo.subpassCount = 1; renderPassInfo.pSubpasses = &amp;subpass; renderPassInfo.dependencyCount = 1; renderPassInfo.pDependencies = &amp;dependency; if (vkCreateRenderPass(m_device.Device(), &amp;renderPassInfo, nullptr, &amp;m_renderPass) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create render pass!&quot;); &#125;&#125; Create Shader ModulesLast time we configured those fixed-function stages, to create a complete pipeline, we still need to create shader modules for vertex shader and fragment shader. My development environment is Windows11 using Visual Studio 2022, the code is simple, but we have to do something else to make it work. 12345678910111213void ArkPipeline::CreateShaderModule(const std::vector&lt;char&gt;&amp; code, VkShaderModule* shaderModule)&#123; VkShaderModuleCreateInfo createInfo&#123;&#125;; createInfo.sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO; createInfo.codeSize = code.size(); createInfo.pCode = reinterpret_cast&lt;const uint32_t*&gt;(code.data()); if (vkCreateShaderModule(m_arkDevice.Device(), &amp;createInfo, nullptr, shaderModule) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create shader module!&quot;); &#125;&#125; We also need a function to read shader file: 1234567891011121314151617181920std::vector&lt;char&gt; ResourceManager::ReadTextFile(const std::filesystem::path&amp; path) const&#123; // std::ios::ate seek to the end std::ifstream file(path, std::ios::ate | std::ios::binary); if (!file.is_open()) &#123; throw std::runtime_error(&quot;failed to open file!&quot;); &#125; const size_t fileSize = static_cast&lt;size_t&gt;(file.tellg()); std::vector&lt;char&gt; buffer(fileSize); file.seekg(0); file.read(buffer.data(), fileSize); file.close(); return buffer;&#125; Unlike earlier APIs, shader code in Vulkan has to be specified in a bytecode format as opposed to human-readable syntax like GLSL and HLSL. This bytecode format is called SPIR-V and is designed to be used with both Vulkan and OpenCL (both Khronos APIs). It is a format that can be used to write graphics and compute shaders. So the shader code we write must be complied into SPIR-V format before we use them, the compilation can be done using glslangValidator.exe or glslc.exe. The advantage of glslc is that it uses the same parameter format as well-known compilers like GCC and Clang and includes some extra functionality like includes. Both of them are already included in the Vulkan SDK. In Visual Studio, I created a batch file to build the shaders and run this batch script as a pre-build event. 123cd %~dp0..\\shadersecho %cd%for %%i in (*.vert *.frag) do ( glslc.exe %%i -o %%i.spv ) We also need to add the shader files to our project and change their Item Type to Custom Build Tool. When the contents of the shader files change, they will be compiled automatically. Finally change .vcxproj file, add a custom clean command to clean the compiled shader files when we clean our project. 1234567891011&lt;Project&gt; ... &lt;Target Name=&quot;CustomClean&quot; BeforeTargets=&quot;CoreClean&quot;&gt; &lt;Message Text=&quot;Clean up compiled spv shaders&quot; Importance=&quot;high&quot; /&gt; &lt;ItemGroup&gt; &lt;_ShaderFilesToDelete Include=&quot;$(ProjectDir)shaders\\*.spv&quot; /&gt; &lt;/ItemGroup&gt; &lt;Delete Files=&quot;@(_ShaderFilesToDelete)&quot; /&gt; &lt;/Target&gt; ...&lt;/Project&gt; That’s all for today, next we will get involved with FrameBuffer and CommandBuffer, then we can finally draw our FIRST triangle!!","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://proton991.github.io/categories/Computer-Graphics/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"Vulkan","slug":"Vulkan","permalink":"https://proton991.github.io/tags/Vulkan/"}]},{"title":"Ark VkRenderer Dev Log 4","slug":"Ark-VkRenderer-Dev-Log-4","date":"2022-07-05T06:15:51.000Z","updated":"2022-07-05T08:16:21.604Z","comments":false,"path":"Ark-VkRenderer-Dev-Log-4/","link":"","permalink":"https://proton991.github.io/Ark-VkRenderer-Dev-Log-4/","excerpt":"","text":"Graphics pipelinesGraphic pipeline overview: The input assembler collects the raw vertex data from the buffers you specify and may also use an index buffer to repeat certain elements without having to duplicate the vertex data itself. The vertex shader is run for every vertex and generally applies transformations to turn vertex positions from model space to screen space. It also passes per-vertex data down the pipeline. The tessellation shaders allow you to subdivide geometry based on certain rules to increase the mesh quality. This is often used to make surfaces like brick walls and staircases look less flat when they are nearby. The geometry shader is run on every primitive (triangle, line, point) and can discard it or output more primitives than came in. This is similar to the tessellation shader, but much more flexible. However, it is not used much in today’s applications because the performance is not that good on most graphics cards except for Intel’s integrated GPUs. The rasterization stage discretizes the primitives into fragments. These are the pixel elements that they fill on the framebuffer. Any fragments that fall outside the screen are discarded and the attributes outputted by the vertex shader are interpolated across the fragments, as shown in the figure. Usually the fragments that are behind other primitive fragments are also discarded here because of depth testing. The fragment shader is invoked for every fragment that survives and determines which framebuffer(s) the fragments are written to and with which color and depth values. It can do this using the interpolated data from the vertex shader, which can include things like texture coordinates and normals for lighting. The color blending stage applies operations to mix different fragments that map to the same pixel in the framebuffer. Fragments can simply overwrite each other, add up or be mixed based upon transparency. Stages with a green color are known as fixed-function stages. These stages allow you to tweak their operations using parameters, but the way they work is predefined. Stages with an orange color on the other hand are programmable, which means that you can upload your own code to the graphics card to apply exactly the operations you want. This allows you to use fragment shaders, for example, to implement anything from texturing and lighting to ray tracers. These programs run on many GPU cores simultaneously to process many objects, like vertices and fragments in parallel. The graphics pipeline in Vulkan is almost completely immutable, so you must recreate the pipeline from scratch if you want to change shaders, bind different framebuffers or change the blend function. Disadvantage: you’ll have to create a number of pipelines that represent all of the different combinations of states you want to use in your rendering operations. Advantages: because all of the operations you’ll be doing in the pipeline are known in advance, the driver can optimize for it much better. Some of the programmable stages are optional, our first goal is to draw a triangle, so we only need vertex shader stage and fragment shader stage. Fixed-function stagesFirst let’s take a look at those fixed-function stages. These stages’ initialization can be done in one function by taking in different parameters(using structs). Our first app is just drawing a triangle, so we create a function to populate default settings to these fixed-function stages. First, we need a struct to wrap all these stages together: 123456789101112131415161718struct PipelineConfigInfo&#123; VkViewport viewport; VkRect2D scissor; VkPipelineViewportStateCreateInfo viewportInfo; VkPipelineInputAssemblyStateCreateInfo inputAssemblyInfo; VkPipelineRasterizationStateCreateInfo rasterizationInfo; VkPipelineMultisampleStateCreateInfo multisampleInfo; VkPipelineColorBlendAttachmentState colorBlendAttachment; VkPipelineColorBlendStateCreateInfo colorBlendInfo; VkPipelineDepthStencilStateCreateInfo depthStencilInfo; VkPipelineLayout pipelineLayout = nullptr; VkRenderPass renderPass = nullptr; uint32_t subpass = 0; PipelineConfigInfo() = default; PipelineConfigInfo(const PipelineConfigInfo&amp;) = delete; PipelineConfigInfo&amp; operator=(const PipelineConfigInfo&amp;) = delete;&#125;; Next, define a function to populate default configurations: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990void ArkPipeline::DefaultPipelineConfigInfo( PipelineConfigInfo&amp; configInfo, uint32_t width, uint32_t height)&#123; configInfo.inputAssemblyInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO; configInfo.inputAssemblyInfo.topology = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST; configInfo.inputAssemblyInfo.primitiveRestartEnable = VK_FALSE; configInfo.viewport.x = 0.0f; configInfo.viewport.y = 0.0f; configInfo.viewport.width = static_cast&lt;float&gt;(width); configInfo.viewport.height = static_cast&lt;float&gt;(height); configInfo.viewport.minDepth = 0.0f; configInfo.viewport.maxDepth = 1.0f; configInfo.scissor.offset = &#123;0, 0&#125;; configInfo.scissor.extent = &#123;width, height&#125;; configInfo.viewportInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO; configInfo.viewportInfo.viewportCount = 1; configInfo.viewportInfo.pViewports = &amp;configInfo.viewport; configInfo.viewportInfo.scissorCount = 1; configInfo.viewportInfo.pScissors = &amp;configInfo.scissor; configInfo.rasterizationInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO; configInfo.rasterizationInfo.depthClampEnable = VK_FALSE; configInfo.rasterizationInfo.rasterizerDiscardEnable = VK_FALSE; configInfo.rasterizationInfo.polygonMode = VK_POLYGON_MODE_FILL; configInfo.rasterizationInfo.lineWidth = 1.0f; configInfo.rasterizationInfo.cullMode = VK_CULL_MODE_NONE; configInfo.rasterizationInfo.frontFace = VK_FRONT_FACE_CLOCKWISE; configInfo.rasterizationInfo.depthBiasEnable = VK_FALSE; configInfo.rasterizationInfo.depthBiasConstantFactor = 0.0f; // Optional configInfo.rasterizationInfo.depthBiasClamp = 0.0f; // Optional configInfo.rasterizationInfo.depthBiasSlopeFactor = 0.0f; // Optional configInfo.multisampleInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO; configInfo.multisampleInfo.sampleShadingEnable = VK_FALSE; configInfo.multisampleInfo.rasterizationSamples = VK_SAMPLE_COUNT_1_BIT; configInfo.multisampleInfo.minSampleShading = 1.0f; // Optional configInfo.multisampleInfo.pSampleMask = nullptr; // Optional configInfo.multisampleInfo.alphaToCoverageEnable = VK_FALSE; // Optional configInfo.multisampleInfo.alphaToOneEnable = VK_FALSE; // Optional configInfo.colorBlendAttachment.colorWriteMask = VK_COLOR_COMPONENT_R_BIT | VK_COLOR_COMPONENT_G_BIT | VK_COLOR_COMPONENT_B_BIT | VK_COLOR_COMPONENT_A_BIT; configInfo.colorBlendAttachment.blendEnable = VK_FALSE; configInfo.colorBlendAttachment.srcColorBlendFactor = VK_BLEND_FACTOR_ONE; // Optional configInfo.colorBlendAttachment.dstColorBlendFactor = VK_BLEND_FACTOR_ZERO; // Optional configInfo.colorBlendAttachment.colorBlendOp = VK_BLEND_OP_ADD; // Optional configInfo.colorBlendAttachment.srcAlphaBlendFactor = VK_BLEND_FACTOR_ONE; // Optional configInfo.colorBlendAttachment.dstAlphaBlendFactor = VK_BLEND_FACTOR_ZERO; // Optional configInfo.colorBlendAttachment.alphaBlendOp = VK_BLEND_OP_ADD; // Optional configInfo.colorBlendInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO; configInfo.colorBlendInfo.logicOpEnable = VK_FALSE; configInfo.colorBlendInfo.logicOp = VK_LOGIC_OP_COPY; // Optional configInfo.colorBlendInfo.attachmentCount = 1; configInfo.colorBlendInfo.pAttachments = &amp;configInfo. colorBlendAttachment; configInfo.colorBlendInfo.blendConstants[0] = 0.0f; // Optional configInfo.colorBlendInfo.blendConstants[1] = 0.0f; // Optional configInfo.colorBlendInfo.blendConstants[2] = 0.0f; // Optional configInfo.colorBlendInfo.blendConstants[3] = 0.0f; // Optional configInfo.depthStencilInfo.sType = VK_STRUCTURE_TYPE_PIPELINE_DEPTH_STENCIL_STATE_CREATE_INFO; configInfo.depthStencilInfo.depthTestEnable = VK_TRUE; configInfo.depthStencilInfo.depthWriteEnable = VK_TRUE; configInfo.depthStencilInfo.depthCompareOp = VK_COMPARE_OP_LESS; configInfo.depthStencilInfo.depthBoundsTestEnable = VK_FALSE; configInfo.depthStencilInfo.minDepthBounds = 0.0f; // Optional configInfo.depthStencilInfo.maxDepthBounds = 1.0f; // Optional configInfo.depthStencilInfo.stencilTestEnable = VK_FALSE; configInfo.depthStencilInfo.front = &#123;&#125;; // Optional configInfo.depthStencilInfo.back = &#123;&#125;; // Optional&#125; Vertex inputThe VkPipelineVertexInputStateCreateInfo structure describes the format of the vertex data that will be passed to the vertex shader. It describes this in roughly two ways: Bindings: spacing between data and whether the data is per-vertex or per-instance (see instancing) Attribute descriptions: type of the attributes passed to the vertex shader, which binding to load them from and at which offset Input assemblyThe VkPipelineInputAssemblyStateCreateInfo struct describes two things: what kind of geometry will be drawn from the vertices and if primitive restart should be enabled. The former is specified in the topology member and can have values like: VK_PRIMITIVE_TOPOLOGY_POINT_LIST: points from vertices VK_PRIMITIVE_TOPOLOGY_LINE_LIST: line from every 2 vertices without reuse VK_PRIMITIVE_TOPOLOGY_LINE_STRIP: the end vertex of every line is used as start vertex for the next line VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST: triangle from every 3 vertices without reuse VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP: the second and third vertex of every triangle are used as first two vertices of the next triangle Viewports and scissorsA viewport basically describes the region of the framebuffer that the output will be rendered to. This will almost always be (0, 0) to (width, height) and in this tutorial that will also be the case. While viewports define the transformation from the image to the framebuffer, scissor rectangles define in which regions pixels will actually be stored. Any pixels outside the scissor rectangles will be discarded by the rasterizer. They function like a filter rather than a transformation. RasterizerThe rasterizer takes the geometry that is shaped by the vertices from the vertex shader and turns it into fragments to be colored by the fragment shader. It also performs depth testing, face culling and the scissor test, and it can be configured to output fragments that fill entire polygons or just the edges (wireframe rendering). All this is configured using the VkPipelineRasterizationStateCreateInfo structure. MultisamplingThe VkPipelineMultisampleStateCreateInfo struct configures multisampling, which is one of the ways to perform anti-aliasing. It works by combining the fragment shader results of multiple polygons that rasterize to the same pixel. This mainly occurs along edges, which is also where the most noticeable aliasing artifacts occur. Because it doesn’t need to run the fragment shader multiple times if only one polygon maps to a pixel, it is significantly less expensive than simply rendering to a higher resolution and then downscaling. Enabling it requires enabling a GPU feature. Depth and stencil testingIf you are using a depth and&#x2F;or stencil buffer, then you also need to configure the depth and stencil tests using VkPipelineDepthStencilStateCreateInfo. Color blendingAfter a fragment shader has returned a color, it needs to be combined with the color that is already in the framebuffer. This transformation is known as color blending and there are two ways to do it: Mix the old and new value to produce a final color Combine the old and new value using a bitwise operation. Pipeline layoutThese uniform values need to be specified during pipeline creation by creating a VkPipelineLayout object. This part is configured in our own application. We will come to this in the next dev log.","categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"Vulkan","slug":"Vulkan","permalink":"https://proton991.github.io/tags/Vulkan/"}]},{"title":"Ark VkRenderer Dev Log 3","slug":"Ark-VkRenderer-Dev-Log-3","date":"2022-07-05T02:45:22.000Z","updated":"2022-07-05T04:55:59.484Z","comments":false,"path":"Ark-VkRenderer-Dev-Log-3/","link":"","permalink":"https://proton991.github.io/Ark-VkRenderer-Dev-Log-3/","excerpt":"","text":"Swap chainCheck for swap chain supportNow we are going to touch another important concepts in Vulkan, swap chain. Before using it, we need to check its extension support, this has already been done when we pick our physical device. 1234567891011121314151617181920212223242526const std::vector&lt;const char*&gt; deviceExtensions = &#123; VK_KHR_SWAPCHAIN_EXTENSION_NAME&#125;;bool ArkDevice::CheckDeviceExtensionSupport(VkPhysicalDevice device)&#123; uint32_t extensionCount; vkEnumerateDeviceExtensionProperties(device, nullptr, &amp;extensionCount, nullptr); std::vector&lt;VkExtensionProperties&gt; availableExtensions(extensionCount); vkEnumerateDeviceExtensionProperties( device, nullptr, &amp;extensionCount, availableExtensions.data()); std::set&lt;std::string&gt; requiredExtensions( deviceExtensions.begin(), deviceExtensions.end()); for (const auto&amp; extension : availableExtensions) &#123; requiredExtensions.erase(extension.extensionName); &#125; return requiredExtensions.empty();&#125; When creating logical device, enable the extension: 12345678void CreateLogicalDevice()&#123; //... createInfo.enabledExtensionCount = static_cast&lt;uint32_t&gt;( deviceExtensions.size()); createInfo.ppEnabledExtensionNames = deviceExtensions.data(); //...&#125; Querying details of swap chain supportJust checking if a swap chain is available is not sufficient, because it may not actually be compatible with our window surface. Creating a swap chain also involves a lot more settings than instance and device creation, so we need to query for some more details before we’re able to proceed. There are basically three kinds of properties we need to check: Basic surface capabilities (min&#x2F;max number of images in swap chain, min&#x2F;max width and height of images) Surface formats (pixel format, color space) Available presentation modes Similar to QueueFamilyIndices, we put these properties in a struct: 123456struct SwapChainSupportDetails&#123; VkSurfaceCapabilitiesKHR m_capabilities; std::vector&lt;VkSurfaceFormatKHR&gt; m_formats; std::vector&lt;VkPresentModeKHR&gt; m_presentModes;&#125;; We need a function to populate this struct: 123456789101112131415161718192021222324252627282930313233SwapChainSupportDetails ArkDevice::QuerySwapChainSupport( VkPhysicalDevice device)&#123; SwapChainSupportDetails details; vkGetPhysicalDeviceSurfaceCapabilitiesKHR( device, m_surface, &amp;details.m_capabilities); uint32_t formatCount; vkGetPhysicalDeviceSurfaceFormatsKHR(device, m_surface, &amp;formatCount, nullptr); if (formatCount != 0) &#123; details.m_formats.resize(formatCount); vkGetPhysicalDeviceSurfaceFormatsKHR( device, m_surface, &amp;formatCount, details.m_formats.data()); &#125; uint32_t presentModeCount; vkGetPhysicalDeviceSurfacePresentModesKHR( device, m_surface, &amp;presentModeCount, nullptr); if (presentModeCount != 0) &#123; details.m_presentModes.resize(presentModeCount); vkGetPhysicalDeviceSurfacePresentModesKHR( device, m_surface, &amp;presentModeCount, details.m_presentModes.data()); &#125; return details;&#125; Choose the right swap chain1234567// Helper functionsVkSurfaceFormatKHR ChooseSwapSurfaceFormat( const std::vector&lt;VkSurfaceFormatKHR&gt;&amp; availableFormats);VkPresentModeKHR ChooseSwapPresentMode( const std::vector&lt;VkPresentModeKHR&gt;&amp; availablePresentModes);VkExtent2D ChooseSwapExtent( const VkSurfaceCapabilitiesKHR&amp; capabilities); After creating swap chain, we need to use class members to store some handles for later use: 1234VkSwapchainKHR m_swapChain;std::vector&lt;VkImage&gt; m_swapChainImages;VkFormat m_swapChainImageFormat;VkExtent2D m_windowExtent; The images were created by the implementation for the swap chain and they will be automatically cleaned up once the swap chain has been destroyed, therefore we don’t need to add any cleanup code. Image viewsVkImageView objects are created based on the VkImage objects that are retrieved after we create swap chain. 12345678910111213141516171819202122232425void ArkSwapChain::CreateImageViews()&#123; m_swapChainImageViews.resize(m_swapChainImages.size()); for (size_t i = 0; i &lt; m_swapChainImages.size(); i++) &#123; VkImageViewCreateInfo viewInfo&#123;&#125;; viewInfo.sType = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO; viewInfo.image = m_swapChainImages[i]; viewInfo.viewType = VK_IMAGE_VIEW_TYPE_2D; viewInfo.format = m_swapChainImageFormat; viewInfo.subresourceRange.aspectMask = VK_IMAGE_ASPECT_COLOR_BIT; viewInfo.subresourceRange.baseMipLevel = 0; viewInfo.subresourceRange.levelCount = 1; viewInfo.subresourceRange.baseArrayLayer = 0; viewInfo.subresourceRange.layerCount = 1; if (vkCreateImageView(m_device.Device(), &amp;viewInfo, nullptr, &amp;m_swapChainImageViews[i]) != VK_SUCCESS) &#123; throw std::runtime_error( &quot;failed to create texture image view!&quot;); &#125; &#125;&#125; Unlike images, the image views were explicitly created by us, so we need to add a similar loop to destroy them again at the end of the program: 1234for (auto imageView : m_swapChainImageViews)&#123; vkDestroyImageView(m_device.Device(), imageView, nullptr);&#125;","categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"Vulkan","slug":"Vulkan","permalink":"https://proton991.github.io/tags/Vulkan/"}]},{"title":"Ark VkRenderer Dev Log 2","slug":"Ark-VkRenderer-Dev-Log-2","date":"2022-07-05T01:03:54.000Z","updated":"2022-07-05T02:27:19.744Z","comments":false,"path":"Ark-VkRenderer-Dev-Log-2/","link":"","permalink":"https://proton991.github.io/Ark-VkRenderer-Dev-Log-2/","excerpt":"","text":"Logical device and queuesAfter selecting a physical device to use we need to set up a logical device to interface with it. The logical device creation process is similar to the instance creation process and describes the features we want to use. We also need to specify which queues to create now that we’ve queried which queue families are available. The creation process involves specifying a bunch of details in structs. The first one is VkDeviceQueueCreateInfo. This structure describes the number of queues we want for a single queue family, The QueueFamily is found by FindQueueFamilies, which is shown in last dev log. Then using a while loop to set each VkDeviceQueueCreateInfo separately. 12345678910float queuePriority = 1.0f;for (uint32_t queueFamily : uniqueQueueFamilies)&#123; VkDeviceQueueCreateInfo queueCreateInfo = &#123;&#125;; queueCreateInfo.sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO; queueCreateInfo.queueFamilyIndex = queueFamily; queueCreateInfo.queueCount = 1; queueCreateInfo.pQueuePriorities = &amp;queuePriority; queueCreateInfos.push_back(queueCreateInfo);&#125; Next, we specify used device features: 12VkPhysicalDeviceFeatures deviceFeatures = &#123;&#125;;deviceFeatures.samplerAnisotropy = VK_TRUE; Here enabling samplerAnisotropy means enhancing the image quality of textures on surfaces through anisotropic filtering (abbreviated AF). Finally, we can create our logical device, create a VkDeviceCreateInfo struct and fill in data. 1234567891011VkDeviceCreateInfo createInfo = &#123;&#125;;createInfo.sType = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO;createInfo.queueCreateInfoCount = static_cast&lt;uint32_t&gt;(queueCreateInfos .size());createInfo.pQueueCreateInfos = queueCreateInfos.data();createInfo.pEnabledFeatures = &amp;deviceFeatures;createInfo.enabledExtensionCount = static_cast&lt;uint32_t&gt;( deviceExtensions.size());createInfo.ppEnabledExtensionNames = deviceExtensions.data(); The last step to specify validation layers in already deprecated, but we still add this for compatibility reasons: 123456789101112// might not really be necessary anymore because device specific validation layers// have been deprecatedif (enableValidationLayers)&#123; createInfo.enabledLayerCount = static_cast&lt;uint32_t&gt;( validationLayers.size()); createInfo.ppEnabledLayerNames = validationLayers.data();&#125;else&#123; createInfo.enabledLayerCount = 0;&#125; Now we are ready to create our logical device: 12345if (vkCreateDevice(m_physicalDevice, &amp;createInfo, nullptr, &amp;m_device) != VK_SUCCESS)&#123; throw std::runtime_error(&quot;failed to create logical device!&quot;);&#125; There’s one more thing to do. The queues are automatically created along with the logical device, but we don’t have a handle to interface with them yet. Add a a class member to store a handle to the graphics queue: 1vkGetDeviceQueue(m_device, indices.m_graphicsFamily, 0, &amp;m_graphicsQueue); Remember to destroy the device before we exit the program, 1vkDestroyDevice(device, nullptr); Window surface and presentation queue To establish the connection between Vulkan and the window system to present results to the screen, we need to use the WSI (Window System Integration) extensions. Here we will use VkSurfaceKHR. We create this surface in our WindowSystem: 123456789void WindowSystem::CreateWindowSurface(VkInstance instance, VkSurfaceKHR* surface)&#123; if (glfwCreateWindowSurface(instance, m_window, nullptr, surface) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create window surface!&quot;); &#125;&#125; Next, we need to query for presentation support, modify IsDeviceSuitable to check both graphics queue and presentation queue support, modify FindQueueFamilies to get presentation support using vkGetPhysicalDeviceSurfaceSupportKHR.","categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"Vulkan","slug":"Vulkan","permalink":"https://proton991.github.io/tags/Vulkan/"}]},{"title":"Ark VkRenderer Dev Log 1","slug":"Ark-VkRenderer-Dev-Log-1","date":"2022-07-04T04:25:25.000Z","updated":"2022-07-04T06:36:30.423Z","comments":false,"path":"Ark-VkRenderer-Dev-Log-1/","link":"","permalink":"https://proton991.github.io/Ark-VkRenderer-Dev-Log-1/","excerpt":"","text":"Enable Validation LayersThe Vulkan API provides very limited error checking for us, passing incorrect values or null pointer are not handled and will cause the program to crash. Vulkan requires us to be explicit about everything. That’s why we need validation layers. They are optional components that can be hooked into Vulkan function calls to apply addition operations, such as: Checking the values of parameters against the specification to detect misuse Tracking creation and destruction of objects to find resource leaks Checking thread safety by tracking the threads that calls originate from Logging every call and its parameters to the standard output Tracing Vulkan calls for profiling and replaying Before we use anything, we need to check whether they are supported. 123456789101112131415161718192021222324252627282930313233343536#ifdef NDEBUG const bool enableValidationLayers = false;#else const bool enableValidationLayers = true;const std::vector&lt;const char*&gt; validationLayers = &#123; &quot;VK_LAYER_KHRONOS_validation&quot;&#125;;bool ArkDevice::CheckValidationLayerSupport()&#123; uint32_t layerCount; vkEnumerateInstanceLayerProperties(&amp;layerCount, nullptr); std::vector&lt;VkLayerProperties&gt; availableLayers(layerCount); vkEnumerateInstanceLayerProperties(&amp;layerCount, availableLayers.data()); for (const char* layerName : validationLayers) &#123; bool layerFound = false; for (const auto&amp; layerProperties : availableLayers) &#123; if (strcmp(layerName, layerProperties.layerName) == 0) &#123; layerFound = true; break; &#125; &#125; if (!layerFound) &#123; return false; &#125; &#125; return true;&#125; We use this function before creating instance: 12345if (enableValidationLayers &amp;&amp; !CheckValidationLayerSupport())&#123; throw std::runtime_error( &quot;validation layers requested, but not available!&quot;);&#125; Message callbackNext, we need to set up a message callback to handle output messages and details, such as deciding which kind of message we would like to see. We have to set up a debug messenger with a callback using the VK_EXT_debug_utils extension, we modify our GetRequiredExtensions() function: 123456789101112131415161718std::vector&lt;const char*&gt; ArkDevice::GetRequiredExtensions()&#123; uint32_t glfwExtensionCount = 0; const char** glfwExtensions; glfwExtensions = glfwGetRequiredInstanceExtensions(&amp;glfwExtensionCount); std::vector&lt;const char*&gt; extensions(glfwExtensions, glfwExtensions + glfwExtensionCount); // add debug messenger related extension if (enableValidationLayers) &#123; extensions.push_back(VK_EXT_DEBUG_UTILS_EXTENSION_NAME); &#125; return extensions;&#125; Now let’s set up our debug messenger. 123456789101112131415161718SetupDebugMessenger()&#123; PopulateDebugMessengerCreateInfo(createInfo); CreateDebugUtilsMessengerEXT();&#125;PopulateDebugMessengerCreateInfo(createInfo) &#123; // createInfo.XXX = ... // fill in data&#125;VkResult CreateDebugUtilsMessengerEXT(VkInstance instance, const VkDebugUtilsMessengerCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDebugUtilsMessengerEXT* pDebugMessenger) &#123; auto func = (PFN_vkCreateDebugUtilsMessengerEXT) vkGetInstanceProcAddr(instance, &quot;vkCreateDebugUtilsMessengerEXT&quot;); if (func != nullptr) &#123; return func(instance, pCreateInfo, pAllocator, pDebugMessenger); &#125; else &#123; return VK_ERROR_EXTENSION_NOT_PRESENT; &#125;&#125; Don’t forget to destroy the debug Messenger before the program exits: 123if (enableValidationLayers) &#123; DestroyDebugUtilsMessengerEXT(instance, debugMessenger, nullptr);&#125; Select Physical deviceAfter creating VkInstance we need to select a graphics card, the process is quite straightforwad: Get all the physical devices that we have. Check one by one and find the suitable one. Here, ‘suitable’ means to check their supported extensions, their properties, their features… (Such as checking whether it supports Raytracing) 123456789101112131415161718192021222324252627282930void ArkDevice::PickPhysicalDevice()&#123; uint32_t deviceCount = 0; vkEnumeratePhysicalDevices(m_instance, &amp;deviceCount, nullptr); if (deviceCount == 0) &#123; throw std::runtime_error( &quot;failed to find GPUs with Vulkan support!&quot;); &#125; std::cout &lt;&lt; &quot;Device count: &quot; &lt;&lt; deviceCount &lt;&lt; std::endl; std::vector&lt;VkPhysicalDevice&gt; devices(deviceCount); vkEnumeratePhysicalDevices(m_instance, &amp;deviceCount, devices.data()); for (const auto&amp; device : devices) &#123; if (IsDeviceSuitable(device)) &#123; m_physicalDevice = device; break; &#125; &#125; if (m_physicalDevice == VK_NULL_HANDLE) &#123; throw std::runtime_error(&quot;failed to find a suitable GPU!&quot;); &#125; vkGetPhysicalDeviceProperties(m_physicalDevice, &amp;properties); std::cout &lt;&lt; &quot;physical device: &quot; &lt;&lt; properties.deviceName &lt;&lt; std::endl;&#125; Almost every operation in Vulkan, anything from drawing to uploading textures, requires commands to be submitted to a queue. There are different types of queues that originate from different queue families and each family of queues allows only a subset of commands. For example, there could be a queue family that only allows processing of compute commands or one that only allows memory transfer related commands. We need to check which queue families are supported by the device and which one of these supports the commands that we want to use. 123456789101112struct QueueFamilyIndices&#123; uint32_t m_graphicsFamily; uint32_t m_presentFamily; bool m_graphicsFamilyHasValue = false; bool m_presentFamilyHasValue = false; bool IsComplete() &#123; return m_graphicsFamilyHasValue &amp;&amp; m_presentFamilyHasValue; &#125;&#125;; Here’s how we find a physical device’s queue family: 123456789101112131415161718192021222324252627282930313233343536373839QueueFamilyIndices ArkDevice::FindQueueFamilies(VkPhysicalDevice device)&#123; QueueFamilyIndices indices; uint32_t queueFamilyCount = 0; vkGetPhysicalDeviceQueueFamilyProperties( device, &amp;queueFamilyCount, nullptr); std::vector&lt;VkQueueFamilyProperties&gt; queueFamilies(queueFamilyCount); vkGetPhysicalDeviceQueueFamilyProperties( device, &amp;queueFamilyCount, queueFamilies.data()); int i = 0; for (const auto&amp; queueFamily : queueFamilies) &#123; if (queueFamily.queueCount &gt; 0 &amp;&amp; queueFamily.queueFlags &amp; VK_QUEUE_GRAPHICS_BIT) &#123; indices.m_graphicsFamily = i; indices.m_graphicsFamilyHasValue = true; &#125; VkBool32 presentSupport = false; vkGetPhysicalDeviceSurfaceSupportKHR( device, i, m_surface, &amp;presentSupport); if (queueFamily.queueCount &gt; 0 &amp;&amp; presentSupport) &#123; indices.m_presentFamily = i; indices.m_presentFamilyHasValue = true; &#125; if (indices.IsComplete()) &#123; break; &#125; i++; &#125; return indices;&#125; The next step is to create a logical device to interface with it, see you next time~~","categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"Vulkan","slug":"Vulkan","permalink":"https://proton991.github.io/tags/Vulkan/"}]},{"title":"Ark VkRenderer Dev Log 0","slug":"Ark-VkRender-Dev-Log-0","date":"2022-07-03T09:21:10.000Z","updated":"2022-07-04T04:25:47.783Z","comments":false,"path":"Ark-VkRender-Dev-Log-0/","link":"","permalink":"https://proton991.github.io/Ark-VkRender-Dev-Log-0/","excerpt":"","text":"VkRenderer from scratchThis renderer is based on a tutorial on youtube (which itself is based on https://vulkan-tutorial.com/). My plan is to finish this in 1 month. Vulkan is a new API that I never used before, so I will explain the main concepts in detail along the way in order to fully understand it. For the theory part I will reference another serial on youtube - Vulkan Essentials. About VulkanVulkan has the following features: Graphics and compute API Cross-platform and cross-device High efficiency and low level explicit (verbose) API Major Vulkan handles: Vulkan instance: VkInstance Physical device: VkPhysicalDevice Logical device: VkDevice Vulkan Extensions 2 types: Instance Extensions: Debug features, OS-specific features, Cross-device&#x2F;instance&#x2F;process memory Device extensions: Capabilities of a physical device(RTX&#x2F;GTX) functions with EXT suffix, e.g. vkCreateDebugUtilsMessengerEXT() OverviewOur FIRST GOAL is to draw a triangle, so how? The answer is roughly about 8 steps in total: Instance and physical device selection Logical device and queue families. Window surface and swap chain. Image views and framebuffers. Render passes. Graphics pipeline. Command pools and command buffers. Main loop. We will build it step by step. First of all, a windowWe will use GLFW as our window API, so first thing todo is to build a WindowSystem, I have done something similar in another OpenGL based renderer, so I will simply paste the code here. 12345678910111213141516171819202122232425262728#pragma once#define GLFW_INCLUDE_VULKAN#include &lt;GLFW/glfw3.h&gt;#include &lt;string&gt;namespace Ark&#123; class WindowSystem &#123; private: void Init(); const int m_width; const int m_height; std::string m_windowName; GLFWwindow* m_window; public: WindowSystem(int w, int h, const std::string&amp; name); ~WindowSystem(); WindowSystem(WindowSystem&amp;&amp;) = default; // Disable copying WindowSystem(const WindowSystem&amp;) = delete; WindowSystem&amp; operator=(const WindowSystem&amp;) = delete; bool ShouldClose() const &#123; return glfwWindowShouldClose(m_window); &#125; &#125;;&#125; And its implementation: 1234567891011121314151617181920212223242526272829303132333435363738#include &quot;WindowSystem.hpp&quot;#include &lt;stdexcept&gt;namespace Ark&#123; WindowSystem::WindowSystem(const int w, const int h, const std::string&amp; name) : m_width(w), m_height(h), m_windowName(name) &#123; Init(); &#125; void WindowSystem::Init() &#123; glfwInit(); glfwWindowHint(GLFW_CLIENT_API, GLFW_NO_API); glfwWindowHint(GLFW_RESIZABLE, GLFW_FALSE); m_window = glfwCreateWindow(m_width, m_height, m_windowName.c_str(), nullptr, nullptr); &#125; WindowSystem::~WindowSystem() &#123; glfwDestroyWindow(m_window); glfwTerminate(); &#125; void WindowSystem::CreateWindowSurface(VkInstance instance, VkSurfaceKHR* surface) &#123; if (glfwCreateWindowSurface(instance, m_window, nullptr, surface) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create window surface!&quot;); &#125; &#125;&#125; We will not get involved with window resizing or input handling when drawing our first triangle, so these functions are enough for us. Let’s create an instanceA VkInstance is an object that connects your application with Vulkan library. This is the very first thing we need to do. The way we use Vulkan APIs is different from OpenGL. In OpenGL we pass information through function parameters, while in Vulkan we pass them through structs. To create a vkInstance, we need 2 structs, VkApplicationInfo &amp; VkInstanceCreateInfo 123456789101112131415161718void ArkDevice::CreateInstance()&#123; VkApplicationInfo appInfo = &#123;&#125;; appInfo.sType = VK_STRUCTURE_TYPE_APPLICATION_INFO; appInfo.pApplicationName = &quot;LittleVulkanEngine App&quot;; appInfo.applicationVersion = VK_MAKE_VERSION(1, 0, 0); appInfo.pEngineName = &quot;No Engine&quot;; appInfo.engineVersion = VK_MAKE_VERSION(1, 0, 0); appInfo.apiVersion = VK_API_VERSION_1_0; VkInstanceCreateInfo createInfo = &#123;&#125;; createInfo.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO; createInfo.pApplicationInfo = &amp;appInfo; if (vkCreateInstance(&amp;createInfo, nullptr, &amp;m_instance) != VK_SUCCESS) &#123; throw std::runtime_error(&quot;failed to create m_instance!&quot;); &#125;&#125; To create an instance, we also need to configure extensions, we need to specify the desired global extensions before creating them. Vulkan is a platform agnostic API, so we need an extension to interface with the window system. The function we need is glfwGetRequiredInstanceExtensions. 1234567891011121314151617std::vector&lt;const char*&gt; ArkDevice::GetRequiredExtensions()&#123; uint32_t glfwExtensionCount = 0; const char** glfwExtensions; glfwExtensions = glfwGetRequiredInstanceExtensions(&amp;glfwExtensionCount); std::vector&lt;const char*&gt; extensions(glfwExtensions, glfwExtensions + glfwExtensionCount); if (enableValidationLayers) &#123; extensions.push_back(VK_EXT_DEBUG_UTILS_EXTENSION_NAME); &#125; return extensions;&#125; And we use vkEnumerateInstanceExtensionProperties to check available extensions before creating instance: 12345678910111213141516171819202122232425262728void ArkDevice::HasGlfwRequiredInstanceExtensions()&#123; uint32_t extensionCount = 0; vkEnumerateInstanceExtensionProperties(nullptr, &amp;extensionCount, nullptr); std::vector&lt;VkExtensionProperties&gt; extensions(extensionCount); vkEnumerateInstanceExtensionProperties(nullptr, &amp;extensionCount, extensions.data()); std::cout &lt;&lt; &quot;available extensions:&quot; &lt;&lt; std::endl; std::unordered_set&lt;std::string&gt; available; for (const auto&amp; extension : extensions) &#123; std::cout &lt;&lt; &quot;\\t&quot; &lt;&lt; extension.extensionName &lt;&lt; std::endl; available.insert(extension.extensionName); &#125; std::cout &lt;&lt; &quot;required extensions:&quot; &lt;&lt; std::endl; auto requiredExtensions = GetRequiredExtensions(); for (const auto&amp; required : requiredExtensions) &#123; std::cout &lt;&lt; &quot;\\t&quot; &lt;&lt; required &lt;&lt; std::endl; if (available.find(required) == available.end()) &#123; throw std::runtime_error(&quot;Missing required glfw extension&quot;); &#125; &#125;&#125; We can see the pattern when we use API like vkEnumerateXXX(): call vkEnumerateXXX() to get the number of XXX. call vkEnumerateXXX() again to get the data of XXX. Finally, don’t forget to call vkDestroyInstance() before the program exits.","categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"Vulkan","slug":"Vulkan","permalink":"https://proton991.github.io/tags/Vulkan/"}]},{"title":"ArkRenderer Dev Log 1","slug":"ArkRenderer-Dev-Log-1","date":"2022-06-22T10:38:31.000Z","updated":"2022-06-22T14:16:01.467Z","comments":false,"path":"ArkRenderer-Dev-Log-1/","link":"","permalink":"https://proton991.github.io/ArkRenderer-Dev-Log-1/","excerpt":"","text":"Wrapping Vertex Array Object &amp; Vertex Buffer ObjectTo start drawing something we have to first give OpenGL some input vertex data. These data are stored in GPU memory, which are managed via so called vertex buffer objects(VBO). A Vertex Array Object (or VAO) is an object that describes how the vertex attributes are stored in a Vertex Buffer Object (or VBO) Using such objects in OpenGL follows the pattern “Gen..&#x2F;Bind…&#x2F;..Enable(use)”, similar to a state machine. So we use OOP to wrap them together to make our code cleaner and improve readability. A vertex attribute is an input variable to a shader that is supplied with per-vertex data. These variable can contain, for example, positions, normals or texture coordinates. We use GLVertexArray 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// GLVertexArray.hclass GLVertexArray&#123;public: enum BufferType : int &#123; Array = GL_ARRAY_BUFFER, Element = GL_ELEMENT_ARRAY_BUFFER &#125;; enum DrawMode : int &#123; Static = GL_STATIC_DRAW, Dynamic = GL_DYNAMIC_DRAW, Stream = GL_STREAM_DRAW &#125;; void Init() noexcept; void AttachBuffer(const BufferType type, const size_t size, const DrawMode mode, const void* data) noexcept; void Bind() const noexcept; void EnableAttribute(const unsigned int index, const int size, const unsigned int offset, const void* data) noexcept; void Delete() noexcept;private: unsigned int m_vao&#123;0&#125;;&#125;;// GLVertexArray.cpp#include &quot;GLVertexArray.h&quot;void GLVertexArray::Init() noexcept&#123; glGenVertexArrays(1, &amp;m_vao);&#125;void GLVertexArray::AttachBuffer(const BufferType type, const size_t size, const DrawMode mode, const void* data) noexcept&#123; unsigned int buffer; glGenBuffers(1, &amp;buffer); glBindBuffer(type, buffer); glBufferData(type, size, data, mode);&#125;void GLVertexArray::Bind() const noexcept&#123; glBindVertexArray(m_vao);&#125;void GLVertexArray::Delete() noexcept&#123; glDeleteVertexArrays(1, &amp;m_vao);&#125;void GLVertexArray::EnableAttribute(const unsigned index, const int size, const unsigned int offset, const void* data) noexcept&#123; glEnableVertexAttribArray(index); glVertexAttribPointer(index, size, GL_FLOAT, GL_FALSE, offset, data);&#125; Shader ClassesShaders are little programs that rest on the GPU, which are run for each specific section of the graphics pipeline. Below is the OpenGL rendering pipeline. There are many stages, each stage takes in input data and output data for next stage. At the beginning, we will only use vertex shader and fragment shader. We use a ShaderStage struct to store each shader stage: 12345678910111213141516171819202122namespace Graphics&#123; const std::unordered_map&lt;std::string, int&gt; TYPE2_GL_ENUM&#123; &#123;&quot;vertex&quot;, GL_VERTEX_SHADER&#125;, &#123;&quot;fragment&quot;, GL_FRAGMENT_SHADER&#125;, &#123;&quot;geometry&quot;, GL_GEOMETRY_SHADER&#125;, &#123;&quot;compute&quot;, GL_COMPUTE_SHADER&#125; &#125;; struct ShaderStage &#123; ShaderStage() noexcept = default; ShaderStage(const std::string&amp; path, const std::string&amp; type) : m_filePath(path), m_type(type) &#123; &#125; std::string m_filePath; std::string m_type; &#125;;&#125;; // namespace Graphics We manipulate shaders via id, which is the return value of glCreateShader(). Uniform variables allow us to pass data to our shaders, the difference between attribute and uniform variable is that attribute variables contain data which is vertex specific so they are reloaded with a new value from the vertex buffer for each shader invocation while the value of uniform variables remains constant across the entire draw call. Here’s how we define a Shader program: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class GLShaderProgram&#123;private: std::unordered_map&lt;std::string, int&gt; m_uniforms; GLuint m_programId&#123;0&#125;; std::string m_programName; void GetUniforms();public: GLShaderProgram(const std::string&amp; programName, const GLuint programId); ~GLShaderProgram(); void Bind() const; void DeleteProgram() const; GLShaderProgram&amp; SetUniformi(const std::string&amp; uniformName, const int value); GLShaderProgram&amp; SetUniformf(const std::string&amp; uniformName, const float value); GLShaderProgram&amp; SetUniform(const std::string&amp; uniformName, const glm::ivec2&amp; value); GLShaderProgram&amp; SetUniform(const std::string&amp; uniformName, const glm::vec2&amp; value); GLShaderProgram&amp; SetUniform(const std::string&amp; uniformName, const glm::vec3&amp; value); GLShaderProgram&amp; SetUniform(const std::string&amp; uniformName, const glm::vec4&amp; value); GLShaderProgram&amp; SetUniform(const std::string&amp; uniformName, const glm::mat3x3&amp; value); GLShaderProgram&amp; SetUniform(const std::string&amp; uniformName, const glm::mat4x4&amp; value); [[nodiscard]] auto GetProgramName() const noexcept &#123; return m_programName; &#125;&#125;;GLShaderProgram::GLShaderProgram(const std::string&amp; programName, const GLuint programID): m_programId(programID), m_programName(programName)&#123; GetUniforms();&#125;void GLShaderProgram::GetUniforms()&#123; int total = -1; glGetProgramiv(m_programId, GL_ACTIVE_UNIFORMS, &amp;total); for (auto i = 0; i &lt; total; i++) &#123; auto nameLen = -1, num = -1; GLenum type = GL_ZERO; char name[100]; glGetActiveUniform(m_programId, static_cast&lt;GLuint&gt;(i), sizeof(name) - 1, &amp;nameLen, &amp;num, &amp;type, name); name[nameLen] = 0; const auto nameStr = std::string(name); m_uniforms.try_emplace(nameStr, glGetUniformLocation(m_programId, name)); &#125;&#125; We use factory pattern to create shaders, GLShaderProgramFactory 123456789101112// GLShaderProgramFactory.hnamespace Graphics&#123; class GLShaderProgramFactory &#123; public: static std::optional&lt;GLShaderProgram&gt; CreateShaderProgram( const std::string&amp; programName, const std::vector&lt;ShaderStage&gt;&amp; stages ); &#125;;&#125;; // namespace Graphics Here’s the implementation of CreateShaderProgram 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748std::optional&lt;GLShaderProgram&gt; GLShaderProgramFactory::CreateShaderProgram( const std::string&amp; programName, const std::vector&lt;ShaderStage&gt;&amp; stages)&#123; std::cout &lt;&lt; &quot;Building shader program &quot; &lt;&lt; programName &lt;&lt; std::endl; std::vector&lt;unsigned int&gt; shaderIds; bool success = true; for (auto&amp; stage : stages) &#123; auto id = glCreateShader(TYPE2_GL_ENUM.at(stage.m_type)); shaderIds.push_back(id); auto shaderCode&#123; ResourceManager::GetInstance().LoadTextFile(stage.m_filePath) &#125;; if (!CompileStage(id, shaderCode, stage.m_type)) &#123; success = false; break; &#125; &#125; if (!success) &#123; std::cerr &lt;&lt; &quot;Shader Compilation failed\\n&quot;; for (const auto id : shaderIds) &#123; glDeleteShader(id); &#125; return std::nullopt; &#125; const unsigned int programId = glCreateProgram(); for (const auto id : shaderIds) &#123; glAttachShader(programId, id); &#125; if (!LinkProgram(programId) || !ValidateProgram(programId)) &#123; for (const auto id : shaderIds) &#123; glDetachShader(programId, id); glDeleteShader(id); &#125; glDeleteProgram(programId); std::cerr &lt;&lt; &quot;Shader Link failed\\n&quot;; return std::nullopt; &#125; for (const auto id : shaderIds) &#123; glDetachShader(programId, id); glDeleteShader(id); &#125; return std::make_optional&lt;GLShaderProgram&gt;(&#123; programName, programId &#125;);&#125; The whole process is straightforward: Load shader source code. Compile shader and check errors. Attach shader and link program. Delete the shaders as they’re linked into our program now and no longer necessary. That’s all for today! Next we will dive into model and meshes!.","categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://proton991.github.io/tags/OpenGL/"}]},{"title":"ArkRenderer Dev Log 0","slug":"ArkRenderer-Dev-Log-0","date":"2022-06-17T09:32:03.000Z","updated":"2022-06-17T12:30:58.301Z","comments":false,"path":"ArkRenderer-Dev-Log-0/","link":"","permalink":"https://proton991.github.io/ArkRenderer-Dev-Log-0/","excerpt":"","text":"Window SystemLot’s of OpenGL tutorials start with teaching people to create a black window. To create windows, we need GLFW, which provides a simple API for creating windows, contexts and surfaces, receiving input and events. Integrating 3rd party libraries in Visual Studio can be done in many ways, I prefer this way: building lib file from source code set include and library directories link libs. Step 2 &amp; 3 are done by setting properties of the project. A windows has many properties that can be configured, such as position, size, but as a starting point, we will not make it that complex. (I will improve it by reading configuration file and set these value). So a basic Window System should be something like this: 12345678910111213141516171819202122232425262728293031323334#pragma oncestruct GLFWwindow; // use forward declarationclass WindowSystem&#123;public: WindowSystem() noexcept = default; WindowSystem(WindowSystem&amp;&amp;) = default; WindowSystem&amp; operator=(WindowSystem&amp;&amp;) = default; ~WindowSystem() &#123; Shutdown(); &#125; // Disable Copying WindowSystem(const WindowSystem&amp;) = delete; WindowSystem&amp; operator=(const WindowSystem&amp;) = delete; GLFWwindow* Init(); void SwapBuffers() const; [[nodiscard]] bool IsCursorVisible() const &#123; return m_showCursor; &#125; [[nodiscard]] bool ShouldClose() const &#123; return m_shouldClose; &#125; void Update(); void Shutdown() const;private: GLFWwindow* m_window&#123; nullptr &#125;; bool m_showCursor&#123; false &#125;; bool m_shouldClose&#123; false &#125;;&#125;; Let’s take a look at the Init() function: 12345678910111213141516171819202122232425262728293031GLFWwindow* WindowSystem::Init()&#123; const int width = 1024; const int height = 768; if (!glfwInit()) &#123; std::cerr &lt;&lt; &quot;Failed to start GLFW\\n&quot;; glfwTerminate(); return nullptr; &#125; glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 4); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 6); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); glfwWindowHint(GLFW_SAMPLES, 4); // Enable 4xMSAA glfwWindowHint(GLFW_RESIZABLE, GL_FALSE); m_window = glfwCreateWindow(1024, 768, &quot;ArkRenderer&quot;, nullptr, nullptr); if (!m_window) &#123; std::cerr &lt;&lt; &quot;Failed to create GLFW m_window.\\n&quot;; glfwTerminate(); return nullptr; &#125; glfwMakeContextCurrent(m_window); glfwFocusWindow(m_window); glfwSwapInterval(1); //Enable Vsync // Center window const auto mode = glfwGetVideoMode(glfwGetPrimaryMonitor()); glfwSetWindowPos(m_window, (mode-&gt;width / 2) - width / 2, (mode-&gt;height / 2) - height / 2); glfwSetInputMode(m_window, GLFW_CURSOR, GLFW_CURSOR_DISABLED); return m_window;&#125; I used ‘magic numbers’, which should be avoided. But no worry about that, I will improve this later. 1234void WindowSystem::SwapBuffers() const&#123; glfwSwapBuffers(m_window);&#125; 123456789101112131415161718192021222324void WindowSystem::Update()&#123; glfwPollEvents(); if (Input::GetInstance().IsKeyPressed(GLFW_KEY_TAB)) &#123; m_showCursor = !m_showCursor; if (m_showCursor) &#123; glfwSetInputMode(m_window, GLFW_CURSOR, GLFW_CURSOR_NORMAL); &#125; else &#123; glfwSetInputMode(m_window, GLFW_CURSOR, GLFW_CURSOR_DISABLED); &#125; &#125; // Check if the m_window needs to be closed if (Input::GetInstance().IsKeyPressed(GLFW_KEY_ESCAPE) || glfwWindowShouldClose(m_window)) &#123; m_shouldClose = true; glfwSetWindowShouldClose(m_window, true); &#125;&#125; SwapBuffers is simple. What is glfwPollEvents? The glfwPollEvents function checks if any events are triggered (like keyboard input or mouse movement events)Update function updates window status according to keyboard input(Input.h). In AkrEngine.cpp, we use a function called ConnectToInput to handle input related with current window: 1234567891011121314151617void ConnectToInput(GLFWwindow* window)&#123; const auto resizeCallback = [](GLFWwindow* w, auto width, auto height) &#123; Input::GetInstance().windowResized(width, height); &#125;; glfwSetWindowSizeCallback(window, resizeCallback); const auto keyCallback = [](GLFWwindow* w, auto key, auto scanCode, auto action, auto mode) &#123; Input::GetInstance().keyPressed(key, scanCode, action, mode); &#125;; glfwSetKeyCallback(window, keyCallback); const auto cursorPosCallback = [](GLFWwindow* w, auto xPos, auto yPos) &#123; Input::GetInstance().mouseMoved(xPos, yPos); &#125;; glfwSetCursorPosCallback(window, cursorPosCallback);&#125; And use our simple Window System like this: 123456789101112131415void ArkEngine::Execute()&#123; while (!m_window.ShouldClose()) &#123; Input::GetInstance().Update(); m_window.Update(); m_renderer.Render(); m_window.SwapBuffers(); &#125; Shutdown();&#125;void ArkEngine::Shutdown() const&#123; m_window.Shutdown();&#125; Finally, we got this: That’s all for today!","categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://proton991.github.io/tags/OpenGL/"}]},{"title":"ArkRenderer Project","slug":"ArkRenderer-Project","date":"2022-06-17T05:51:32.000Z","updated":"2022-06-17T09:18:05.251Z","comments":false,"path":"ArkRenderer-Project/","link":"","permalink":"https://proton991.github.io/ArkRenderer-Project/","excerpt":"","text":"This article will be updated during the development OverviewArk Renderer is a 3D rendering engine, I built this by referencing OpenGL-Renderer, it’s my first computer graphic project, so it’s difficult for me to start from scratch on my own. So I intend to build my project based on other projects, the final code may look similar, but I will dive deep into the code and figure out how it works. I will write dev logs along the way. OpengGL programming and basic rendering techniques will be covered. Project StructureThe 3d engine is composed of several sub-systems. They are Window System Render System GUI System The render system is the core of the renderer. I will create “wrappers” for raw OpenGL code and pipeline. Shaders, textures, scenes and other resources will be loaded from disk and cached in memory during runtime, so a ResourceManager is needed.","categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://proton991.github.io/tags/OpenGL/"}]},{"title":"Hello World","slug":"hello-world","date":"2022-06-17T03:00:36.044Z","updated":"2022-06-17T03:00:36.044Z","comments":true,"path":"hello-world/","link":"","permalink":"https://proton991.github.io/hello-world/","excerpt":"","text":"My first hexo blog.Keep doing and do it well.","categories":[{"name":"Talk","slug":"Talk","permalink":"https://proton991.github.io/categories/Talk/"}],"tags":[]},{"title":"LearnCpp-day0","slug":"LearnCpp-day0","date":"2022-03-15T05:18:53.000Z","updated":"2022-06-17T03:00:36.044Z","comments":false,"path":"LearnCpp-day0/","link":"","permalink":"https://proton991.github.io/LearnCpp-day0/","excerpt":"","text":"Learn CPP - OverviewC++ syntax is so complicated that I can’t grasp all of them, so I decided to learn c++ by coding some projects (apart form CG proects). Resources: MyTinySTL Cpp Interview TheAlgorithms&#x2F;C-Plus-Plus LeetCode C++ Learning Schedule Build my own version of STL. Build algorithm libarary using c++.","categories":[{"name":"Cpp","slug":"Cpp","permalink":"https://proton991.github.io/categories/Cpp/"}],"tags":[{"name":"c++","slug":"c","permalink":"https://proton991.github.io/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"https://proton991.github.io/tags/algorithm/"},{"name":"c++ STL","slug":"c-STL","permalink":"https://proton991.github.io/tags/c-STL/"}]},{"title":"RayTraycing-day0","slug":"RayTraycing-day0","date":"2022-03-14T12:27:21.000Z","updated":"2022-06-17T03:00:36.044Z","comments":false,"path":"RayTraycing-day0/","link":"","permalink":"https://proton991.github.io/RayTraycing-day0/","excerpt":"","text":"Overview: Learn Raytracing - from theory to practiceRay tracing is a method of graphics rendering that simulates the physical behavior of light. We can produce photorealistic images using ray tracing algorithms. I decided to learn the whole process of rendering from scratch and finally build my own raytracer. Resources: Scratchapixel Graphics Codex TU Wien Rendering Course Fundamentals of Computer Graphics, Fourth Edition (2016) Physically Based Rendering From Theory to Implementation (2016) Projects: Ray Tracing in One Weekend Smallpaint GLSL-PathTracer PSRayTracing monte-carlo-ray-tracer vk_mini_path_tracer Learning Schedule: LO0: Basics concepts, algorithms in computer graphics&#x2F;rendering. LO1: Follow Ray Tracing in One Weekend Series and code with it. LO2: Refactor the code in LO1 (referencing PSRayTracing and Smallpaint), build a retracer with GUI in which you can select scene and configure paramenters for raytracer. LO3: Learn OpenGL and Read the source code of GLSL-PathTracer thoroughly. LO4: Learn Vulkan and follow the tutorial vk_mini_path_tracer and finally build a Vulkan-pathtracer.","categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"}],"tags":[{"name":"ray-tracing","slug":"ray-tracing","permalink":"https://proton991.github.io/tags/ray-tracing/"},{"name":"computer-graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/tags/computer-graphics/"}]}],"categories":[{"name":"computer graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/categories/computer-graphics/"},{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://proton991.github.io/categories/Computer-Graphics/"},{"name":"Talk","slug":"Talk","permalink":"https://proton991.github.io/categories/Talk/"},{"name":"Cpp","slug":"Cpp","permalink":"https://proton991.github.io/categories/Cpp/"}],"tags":[{"name":"Renderer","slug":"Renderer","permalink":"https://proton991.github.io/tags/Renderer/"},{"name":"Vulkan","slug":"Vulkan","permalink":"https://proton991.github.io/tags/Vulkan/"},{"name":"OpenGL","slug":"OpenGL","permalink":"https://proton991.github.io/tags/OpenGL/"},{"name":"c++","slug":"c","permalink":"https://proton991.github.io/tags/c/"},{"name":"algorithm","slug":"algorithm","permalink":"https://proton991.github.io/tags/algorithm/"},{"name":"c++ STL","slug":"c-STL","permalink":"https://proton991.github.io/tags/c-STL/"},{"name":"ray-tracing","slug":"ray-tracing","permalink":"https://proton991.github.io/tags/ray-tracing/"},{"name":"computer-graphics","slug":"computer-graphics","permalink":"https://proton991.github.io/tags/computer-graphics/"}]}